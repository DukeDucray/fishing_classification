{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to extract data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, file_names):\n",
    "    tables=[]\n",
    "    for file_name in file_names:\n",
    "        table = pd.read_csv(f'../{path}/{file_name}.csv')\n",
    "        table['type']=f'{file_name}'\n",
    "        tables.append(table)\n",
    "    return pd.concat(tables)\n",
    "\n",
    "path='data/raw_data'\n",
    "file_names = ['trawlers', 'drifting_longlines', 'fixed_gear', 'pole_and_line', 'purse_seines', 'trollers', 'unknown']\n",
    "\n",
    "df = get_data(path, file_names)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mmsi'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unknown (-1 in is_fishing column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['is_fishing'] > -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_fishing'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OHE 'type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output =False)\n",
    "\n",
    "# Fit encoder\n",
    "ohe.fit(df[['type']])\n",
    "\n",
    "# Transform the current \"Alley\" column\n",
    "df[ohe.get_feature_names_out()] = ohe.transform(df[['type']])\n",
    "\n",
    "# Drop the column \"Alley\" which has been encoded\n",
    "df.drop(columns = [\"type\", \"source\"], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting is_fishing to Binary (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fishing = df\n",
    "df_fishing['is_fishing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round the decimals so that number becomes 0 or 1\n",
    "df_fishing.loc[:, ('is_fishing')] = round(df_fishing.loc[:, ('is_fishing')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the unique values\n",
    "df_fishing['is_fishing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fishing.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting timestamp to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fishing['timestamp'] = pd.to_datetime(df_fishing['timestamp'], unit='s')\n",
    "df_fishing.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fishing.rename(columns={\"timestamp\": \"date\"}, inplace=True)\n",
    "df_fishing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fishing['year'] = df_fishing['date'].dt.year\n",
    "# 12 columns for month\n",
    "df_fishing['month'] = df_fishing['date'].dt.month\n",
    "#df_fishing['day'] = df_fishing['date'].dt.day\n",
    "# 7 columns for days\n",
    "df_fishing['day_of_week'] = df_fishing['date'].dt.day_of_week\n",
    "#df_fishing['day_of_year'] = df_fishing['date'].dt.day_of_year\n",
    "df_fishing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Angular distance for the days of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fishing['day_of_week_sin'] = np.sin(df_fishing['day_of_week'] * (2 * np.pi / 7))\n",
    "df_fishing['day_of_week_cos'] = np.cos(df_fishing['day_of_week'] * (2 * np.pi / 7))\n",
    "df_fishing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTC converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "def get_utc_offset_from_longitude(longitude):\n",
    "    timezone = pytz.timezone(pytz.country_timezones(\"US\")[0])  # You can replace \"US\" with the appropriate country code\n",
    "    now = datetime.now(timezone)\n",
    "    utc_offset = now.utcoffset().total_seconds() / 3600\n",
    "    return utc_offset\n",
    "\n",
    "df_fishing['utc_offset'] = df_fishing['lon'].apply(get_utc_offset_from_longitude)\n",
    "df_fishing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output =False)\n",
    "\n",
    "# Fit encoder\n",
    "ohe.fit(df_fishing[['day_of_week']])\n",
    "\n",
    "# Transform the current \"Alley\" column\n",
    "df_fishing[ohe.get_feature_names_out()] = ohe.transform(df_fishing[['day_of_week']])\n",
    "\n",
    "# Drop the column \"Alley\" which has been encoded\n",
    "df_fishing.drop(columns = [\"day_of_week\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fishing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fishing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the value counts of 'mmsi'\n",
    "mmsi_counts = df_fishing['mmsi'].value_counts()\n",
    "\n",
    "# Create a boolean mask for filtering mmsi values with counts less than or equal to 20\n",
    "mask = mmsi_counts > 20\n",
    "\n",
    "# Get the mmsi values that meet the condition\n",
    "selected_mmsi = mmsi_counts[mask].index\n",
    "\n",
    "# Use the isin() method to filter the DataFrame based on selected_mmsi\n",
    "filtered_fishing_df = df_fishing[df_fishing['mmsi'].isin(selected_mmsi)]\n",
    "filtered_fishing_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining X features and y target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fishing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with NAN values\n",
    "df_fishing_clean = df_fishing.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fishing_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X - the features and Y - the target\n",
    "X = df_fishing_clean.drop(columns=['date', 'is_fishing', 'utc_offset'])\n",
    "y = df_fishing_clean['is_fishing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import r_regression\n",
    "corr = r_regression(X, y)\n",
    "col_names = list(X.columns)\n",
    "df_corr = pd.DataFrame(corr, col_names)\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as mp\n",
    "import pandas as pd\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_fishing_clean.drop(columns=['date', 'utc_offset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting correlation heatmap\n",
    "dataplot=sb.heatmap(data.corr())\n",
    "  \n",
    "# displaying heatmap\n",
    "mp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split between train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 0 - Instantiate and fit Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Step 1 - Scale/Transform\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, learning_curve, train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "model = LogisticRegression(max_iter=1000).fit(X,y)\n",
    "\n",
    "# Score the model\n",
    "# LogisticRegression will default scoring to accuracy.\n",
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to CSV for quick access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '../data/preprocessed'\n",
    "output_file = 'preproc.csv'\n",
    "\n",
    "# Construct the full path\n",
    "output_path = f'{output_folder}/{output_file}'\n",
    "\n",
    "# Save the DataFrame to the specified path\n",
    "df_fishing.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map data on world map with geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = [Point(xy) for xy in zip(df_fishing['lon'], df_fishing['lat'])]\n",
    "crs = {'init':'epsg:4326'}\n",
    "geo_df = gpd.GeoDataFrame(df_fishing, #specify our data\n",
    "                          crs=crs, #specify our coordinate reference system\n",
    "                          geometry=geometry) #specify the geometry list we created\n",
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping one boat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boat = geo_df._get_value(60649, 'mmsi')\n",
    "one_boat = geo_df.loc[geo_df['mmsi']== boat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting world map data from geo pandas\n",
    "worldmap = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "\n",
    "# Creating axes and plotting world map\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "worldmap.plot(color=\"lightgrey\", ax=ax)\n",
    "\n",
    "# Plotting Longitudes and Latitudes of one boat\n",
    "x = one_boat['lon']\n",
    "y = one_boat['lat']\n",
    "plt.scatter(x, y, cmap='autumn')\n",
    "\n",
    "# Creating axis limits and title\n",
    "plt.xlim([-180, 180])\n",
    "plt.ylim([-90, 90])\n",
    "\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping all boats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating axes and plotting world map\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "worldmap.plot(color=\"lightgrey\", ax=ax)\n",
    "\n",
    "# Plotting Longitudes and Latitudes of one boat\n",
    "x = geo_df['lon']\n",
    "y = geo_df['lat']\n",
    "boats = geo_df['mmsi']\n",
    "plt.scatter(x, y, c=boats, cmap='autumn')\n",
    "\n",
    "# Creating axis limits and title\n",
    "plt.xlim([-180, 180])\n",
    "plt.ylim([-90, 90])\n",
    "\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fishing_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
